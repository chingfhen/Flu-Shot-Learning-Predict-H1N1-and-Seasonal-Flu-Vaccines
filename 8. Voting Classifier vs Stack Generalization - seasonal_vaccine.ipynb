{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf57f04",
   "metadata": {},
   "source": [
    "# ABOUT:\n",
    "- this notebook:\n",
    "    - compared voting classifier and stacked generalisation against base estimators\n",
    "        1. Soft voting with voting classifier will combine estimators by taking the **weighted average probabilities**\n",
    "        2. Stacked generalization trains a final estimator using the **predictions of base estimators as input**\n",
    "- insight:\n",
    "    - xgboost base estimator out performed both stacking and voting **stacking and voting does not always yield gains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da902873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seasonal_vaccine'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(r\"C:\\Users\\tanch\\Documents\\Coding Competitions\\DataDriven\\Flu Shot Learning\\local\\data\\cleaned_train_set.csv\",index_col = \"respondent_id\")\n",
    "target_labels = ['h1n1_vaccine', 'seasonal_vaccine']\n",
    "X = train[[col for col in train.columns if col not in target_labels]]\n",
    "y = train[target_labels[1]]\n",
    "y.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbb5260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.25, stratify =y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54601305",
   "metadata": {},
   "source": [
    "### declare base estimators\n",
    "- they are using the best parameters found in optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900a82b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25195fb6d30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cv_seasonal_best_params = {\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"iterations\" :  3000,\n",
    "    'depth': 4, \n",
    "    'rsm': 0.93789016484649, \n",
    "    'l2_leaf_reg': 7.847914167208884, \n",
    "    'auto_class_weights': 'SqrtBalanced',\n",
    "    \"loss_function\" : \"Logloss\",\n",
    "    \"verbose\":False,\n",
    "    \"task_type\" : \"CPU\",\n",
    "    \"eval_metric\":\"AUC\"\n",
    "}\n",
    "cb = CatBoostClassifier()\n",
    "cb.set_params(**cv_seasonal_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b5bc12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=0.43000000000000005,\n",
       "              eval_metric='auc', gamma=0, gpu_id=None, importance_type='gain',\n",
       "              interaction_constraints=None, learning_rate=0.014239918514545242,\n",
       "              max_delta_step=None, max_depth=5, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=962, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, reg_alpha=1,\n",
       "              reg_lambda=5, scale_pos_weight=None, subsample=0.71,\n",
       "              tree_method=None, validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_seasonal_best_params = {\n",
    "    'learning_rate': 0.014239918514545242,\n",
    "    'max_depth': 5,\n",
    "    'reg_alpha': 1,\n",
    "    'reg_lambda': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'gamma': 0,\n",
    "    'colsample_bytree': 0.43000000000000005,\n",
    "    'subsample': 0.71,\n",
    "    'n_estimators': 962,\n",
    "    'eval_metric': 'auc'\n",
    "}\n",
    "xgb = XGBClassifier()\n",
    "xgb.set_params(**xgb_seasonal_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff73d5",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed92de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219a33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VotingClassifier(estimators = [(\"cb\",cb),(\"xgb\",xgb)],\n",
    "                      voting = \"soft\",            \n",
    "                      weights = None ,             # take equal weights\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa60475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scores = {}\n",
    "for name,model in zip([\"catboost\",\"xgboost\",\"voting classifier\"],[cb,xgb,vc]):\n",
    "    model.fit(train_x, train_y)\n",
    "    y_pred = model.predict_proba(test_x)\n",
    "    scores[name] = roc_auc_score(test_y,y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffce58b",
   "metadata": {},
   "source": [
    "### results\n",
    "- voting classifier wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4dadcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost              0.871051\n",
       "voting classifier    0.870871\n",
       "catboost             0.869629\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(scores).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed82da2",
   "metadata": {},
   "source": [
    "# StackingClassifier\n",
    "- we use two different final estimators to see if it matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9964535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "final_estimator = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "144b2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "sc2 = StackingClassifier(estimators = [(\"cb\",cb),(\"xgb\",xgb)],\n",
    "                        final_estimator = final_estimator,\n",
    "                        stack_method = \"predict_proba\" ,          # predict_proba is called on the base estimators as input for final estimator\n",
    "                        n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8925234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc2.fit(train_x, train_y)\n",
    "y_pred = sc2.predict_proba(test_x)\n",
    "scores[\"Stacking_final_logistic\"] = roc_auc_score(test_y,y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837da6d",
   "metadata": {},
   "source": [
    "# Results\n",
    "- **stacking and voting did not improve performance** here, xgboost was best performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "059baa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost                    0.871051\n",
       "Stacking_final_logistic    0.870937\n",
       "voting classifier          0.870871\n",
       "catboost                   0.869629\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(scores).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb89934",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe8135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sc2, open(r\"C:\\Users\\tanch\\Documents\\Coding Competitions\\DataDriven\\Flu Shot Learning\\local\\model\\seasonal_vaccine_stacking.pkl\", 'wb'))\n",
    "pickle.dump(vc, open(r\"C:\\Users\\tanch\\Documents\\Coding Competitions\\DataDriven\\Flu Shot Learning\\local\\model\\seasonal_vaccine_voting.pkl\", 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31cedc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
